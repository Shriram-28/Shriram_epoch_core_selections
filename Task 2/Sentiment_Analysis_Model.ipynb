{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9503ee0-5fc7-406c-b3e8-30a9a2f4f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "# Packages for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Packages for modeling\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2258d7b-a965-4549-b2b6-47725b97b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sentiment_analysis_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80d9b7b4-8509-4b85-9c33-d283b2abb92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I AM REALLY FRUSTRATED BECAUSE YOU CONSTANTLY ...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IT MAKES ME UPSET THAT YOU NEVER TAKE RESPONSI...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I CANNOT BELIEVE YOU MISSED ANOTHER DEADLINE A...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IT ANNOYS ME WHEN YOU INTERRUPT DURING MEETING...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I AM TIRED OF YOUR EXCUSES EVERY TIME SOMETHIN...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IT UPSETS ME THAT YOU ALWAYS ARRIVE LATE AND Y...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I AM REALLY ANGRY BECAUSE YOU NEVER PREPARE FO...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IT INFURIATES ME THAT YOU NEVER APPRECIATE THE...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I CANNOT STAND HOW YOU ALWAYS TALK DOWN TO PEO...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IT IS VERY DISAPPOINTING THAT YOU NEVER FOLLOW...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I AM VERY HAPPY BECAUSE YOU ALWAYS LISTEN CARE...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IT IS WONDERFUL HOW YOU ALWAYS COME PREPARED A...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I APPRECIATE HOW YOU ALWAYS OFFER TO HELP AND ...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IT IS FANTASTIC THAT YOU ALWAYS HAVE A POSITIV...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I AM GRATEFUL FOR YOUR SUPPORT AND YOU ALWAYS ...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IT MAKES ME HAPPY THAT YOU ALWAYS RECOGNIZE TH...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I AM REALLY IMPRESSED BY YOUR CREATIVITY AND Y...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IT IS AMAZING HOW YOU ALWAYS STAY CALM UNDER P...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I AM THANKFUL FOR YOUR RELIABILITY AND YOU ALW...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IT IS GREAT THAT YOU ALWAYS COMMUNICATE CLEARL...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>THE MEETING TODAY COVERED A LOT OF IMPORTANT P...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>YOUR PRESENTATION WAS CLEAR AND CONCISE AND IT...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I APPRECIATE THE FEEDBACK YOU PROVIDED AND IT ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>THE EVENT YESTERDAY WAS WELLORGANIZED AND THE ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>YOUR REPORT WAS THOROUGH AND DETAILED INCLUDIN...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I FOUND YOUR ARTICLE INTERESTING AND WELLWRITT...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>THE TRAINING SESSION WAS USEFUL PROVIDING PRAC...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>YOUR EMAIL WAS CLEAR AND INFORMATIVE ADDRESSIN...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I ATTENDED THE WORKSHOP YOU RECOMMENDED AND IT...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>THE FEEDBACK SESSION WAS PRODUCTIVE ALLOWING F...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 line sentiment\n",
       "0   I AM REALLY FRUSTRATED BECAUSE YOU CONSTANTLY ...     Angry\n",
       "1   IT MAKES ME UPSET THAT YOU NEVER TAKE RESPONSI...     Angry\n",
       "2   I CANNOT BELIEVE YOU MISSED ANOTHER DEADLINE A...     Angry\n",
       "3   IT ANNOYS ME WHEN YOU INTERRUPT DURING MEETING...     Angry\n",
       "4   I AM TIRED OF YOUR EXCUSES EVERY TIME SOMETHIN...     Angry\n",
       "5   IT UPSETS ME THAT YOU ALWAYS ARRIVE LATE AND Y...     Angry\n",
       "6   I AM REALLY ANGRY BECAUSE YOU NEVER PREPARE FO...     Angry\n",
       "7   IT INFURIATES ME THAT YOU NEVER APPRECIATE THE...     Angry\n",
       "8   I CANNOT STAND HOW YOU ALWAYS TALK DOWN TO PEO...     Angry\n",
       "9   IT IS VERY DISAPPOINTING THAT YOU NEVER FOLLOW...     Angry\n",
       "10  I AM VERY HAPPY BECAUSE YOU ALWAYS LISTEN CARE...     Happy\n",
       "11  IT IS WONDERFUL HOW YOU ALWAYS COME PREPARED A...     Happy\n",
       "12  I APPRECIATE HOW YOU ALWAYS OFFER TO HELP AND ...     Happy\n",
       "13  IT IS FANTASTIC THAT YOU ALWAYS HAVE A POSITIV...     Happy\n",
       "14  I AM GRATEFUL FOR YOUR SUPPORT AND YOU ALWAYS ...     Happy\n",
       "15  IT MAKES ME HAPPY THAT YOU ALWAYS RECOGNIZE TH...     Happy\n",
       "16  I AM REALLY IMPRESSED BY YOUR CREATIVITY AND Y...     Happy\n",
       "17  IT IS AMAZING HOW YOU ALWAYS STAY CALM UNDER P...     Happy\n",
       "18  I AM THANKFUL FOR YOUR RELIABILITY AND YOU ALW...     Happy\n",
       "19  IT IS GREAT THAT YOU ALWAYS COMMUNICATE CLEARL...     Happy\n",
       "20  THE MEETING TODAY COVERED A LOT OF IMPORTANT P...   Neutral\n",
       "21  YOUR PRESENTATION WAS CLEAR AND CONCISE AND IT...   Neutral\n",
       "22  I APPRECIATE THE FEEDBACK YOU PROVIDED AND IT ...   Neutral\n",
       "23  THE EVENT YESTERDAY WAS WELLORGANIZED AND THE ...   Neutral\n",
       "24  YOUR REPORT WAS THOROUGH AND DETAILED INCLUDIN...   Neutral\n",
       "25  I FOUND YOUR ARTICLE INTERESTING AND WELLWRITT...   Neutral\n",
       "26  THE TRAINING SESSION WAS USEFUL PROVIDING PRAC...   Neutral\n",
       "27  YOUR EMAIL WAS CLEAR AND INFORMATIVE ADDRESSIN...   Neutral\n",
       "28  I ATTENDED THE WORKSHOP YOU RECOMMENDED AND IT...   Neutral\n",
       "29  THE FEEDBACK SESSION WAS PRODUCTIVE ALLOWING F...   Neutral"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b969e633-2813-4aef-8884-eb2152a1f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "def sentiment_analysis(text, word_counts, class_priors, class_probs):\n",
    "  \"\"\"\n",
    "  This function performs sentiment analysis on a text using word counts, class priors, and class probabilities for three sentiment classes (Angry, Happy, Neutral).\n",
    "\n",
    "  Args:\n",
    "      text (str): The text to analyze for sentiment.\n",
    "      word_counts (dict): A dictionary mapping words to their counts in each sentiment class document.\n",
    "      class_priors (dict): A dictionary mapping sentiment classes (Angry, Happy, Neutral) to their prior probabilities.\n",
    "      class_probs (dict): A dictionary mapping sentiment classes to dictionaries mapping words to their conditional probabilities.\n",
    "\n",
    "  Returns:\n",
    "      str: The predicted sentiment class (Angry, Happy, or Neutral).\n",
    "  \"\"\"\n",
    "\n",
    "  # Preprocess the text (optional)\n",
    "  # - Convert to lowercase\n",
    "  # - Remove punctuation\n",
    "  text = text.lower()\n",
    "\n",
    "  # Split the text into words\n",
    "  words = text.split()\n",
    "\n",
    "  # Calculate probabilities for each sentiment class\n",
    "  angry_prob = class_priors[\"Angry\"]\n",
    "  happy_prob = class_priors[\"Happy\"]\n",
    "  neutral_prob = class_priors[\"Neutral\"]\n",
    "  for word in words:\n",
    "    if word in word_counts:\n",
    "      angry_prob += log(class_probs[\"Angry\"].get(word, 0.001))  # Add Laplace smoothing\n",
    "      happy_prob += log(class_probs[\"Happy\"].get(word, 0.001))\n",
    "      neutral_prob += log(class_probs[\"Neutral\"].get(word, 0.001))\n",
    "  print(f'angry_prob is {angry_prob}')\n",
    "  print(f'happy_prob is {happy_prob}') \n",
    "  print(f'neutral_prob is {neutral_prob}')  \n",
    "  # Classify based on the highest probability\n",
    "  max_prob = max(angry_prob, happy_prob, neutral_prob)\n",
    "  if max_prob == angry_prob:\n",
    "    return \"Angry\"\n",
    "  elif max_prob == happy_prob:\n",
    "    return \"Happy\"\n",
    "  else:\n",
    "    return \"Neutral\"\n",
    "\n",
    "def train(angry_df, happy_df, neutral_df):\n",
    "    \"\"\"\n",
    "    This function trains the sentiment analysis model for three sentiment classes by building word counts, class priors, and class probabilities.\n",
    "\n",
    "    Args:\n",
    "        angry_df (pandas.DataFrame): A DataFrame containing text documents labeled as Angry in a 'text' column.\n",
    "        happy_df (pandas.DataFrame): A DataFrame containing text documents labeled as Happy in a 'text' column.\n",
    "        neutral_df (pandas.DataFrame): A DataFrame containing text documents labeled as Neutral in a 'text' column.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the trained model (word_counts, class_priors, class_probs).\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract text from DataFrames (assuming 'text' column contains the documents)\n",
    "    angry_text = angry_df['line'].tolist()\n",
    "    happy_text = happy_df['line'].tolist()\n",
    "    neutral_text = neutral_df['line'].tolist()\n",
    "\n",
    "    # Count word occurrences in each sentiment class\n",
    "    angry_word_counts = Counter()\n",
    "    happy_word_counts = Counter()\n",
    "    neutral_word_counts = Counter()\n",
    "    for doc in angry_text:\n",
    "        angry_word_counts.update(doc.lower().split())\n",
    "    for doc in happy_text:\n",
    "        happy_word_counts.update(doc.lower().split())\n",
    "    for doc in neutral_text:\n",
    "        neutral_word_counts.update(doc.lower().split())\n",
    "\n",
    "    # Combine word counts from all classes\n",
    "    all_word_counts = dict(angry_word_counts + happy_word_counts + neutral_word_counts)\n",
    "\n",
    "    # Calculate total word counts for each class\n",
    "    total_angry_words = sum(angry_word_counts.values())\n",
    "    total_happy_words = sum(happy_word_counts.values())\n",
    "    total_neutral_words = sum(neutral_word_counts.values())\n",
    "\n",
    "    # Calculate class priors\n",
    "    class_priors = {\n",
    "        \"Angry\": len(angry_text) / (len(angry_text) + len(happy_text) + len(neutral_text)),\n",
    "        \"Happy\": len(happy_text) / (len(angry_text) + len(happy_text) + len(neutral_text)),\n",
    "        \"Neutral\": len(neutral_text) / (len(angry_text) + len(happy_text) + len(neutral_text))\n",
    "    }\n",
    "\n",
    "    # Calculate class conditional probabilities with Laplace smoothing\n",
    "    class_probs = {\n",
    "        \"Angry\": {word: (count + 1) / (total_angry_words + len(all_word_counts)) for word, count in angry_word_counts.items()},\n",
    "        \"Happy\": {word: (count + 1) / (total_happy_words + len(all_word_counts)) for word, count in happy_word_counts.items()},\n",
    "        \"Neutral\": {word: (count + 1) / (total_neutral_words + len(all_word_counts)) for word, count in neutral_word_counts.items()}\n",
    "    }\n",
    "\n",
    "    # Return the trained model data\n",
    "    return {\"word_counts\": all_word_counts, \"class_priors\": class_priors, \"class_probs\": class_probs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "426da265-b94d-4926-88f9-27c216e8f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_1 =  df['sentiment'] == 'Angry'\n",
    "Angry_df = df[filt_1]\n",
    "\n",
    "filt_2 =  df['sentiment'] == 'Happy'\n",
    "Happy_df = df[filt_2]\n",
    "\n",
    "filt_3 =  df['sentiment'] == 'Neutral'\n",
    "Neutral_df = df[filt_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f61de873-b645-47ac-a112-4f190b095c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_dict = train(Angry_df,Happy_df,Neutral_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2af0f947-61c3-48e8-8448-fe13434f502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_1 = \"I AM REALLY ANNOYED BY YOUR CONSTANT COMPLAINING AND YOU NEVER OFFER ANY SOLUTIONS WHICH IS VERY UNHELPFUL AND NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19199b95-8cde-4f90-87ce-3c9499a65671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry_prob is -59.156608349332785\n",
      "happy_prob is -58.95556569147118\n",
      "neutral_prob is -74.30199204573346\n"
     ]
    }
   ],
   "source": [
    "#text, word_counts, class_priors, class_probs\n",
    "#{\"word_counts\": all_word_counts, \"class_priors\": class_priors, \"class_probs\": class_probs}\n",
    "line_1_class = sentiment_analysis(line_1,naive_bayes_dict.get('word_counts'),naive_bayes_dict.get('class_priors'),naive_bayes_dict.get('class_probs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "765bfa73-5ae7-41bd-b2be-adc3f45d8397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happy'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_1_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8f4f2ec-077d-4292-bd43-652d63946395",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_2 = \"IT IS FRUSTRATING THAT YOU NEVER PAY ATTENTION DURING DISCUSSIONS AND YOUR LACK OF ATTENTION IS REALLY AFFECTING OUR PROGRESS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32bb1bea-226e-42b0-a890-d1cde8bd6ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry_prob is -69.30714396213065\n",
      "happy_prob is -77.7889879525025\n",
      "neutral_prob is -87.05193816907583\n"
     ]
    }
   ],
   "source": [
    "line_2_class = sentiment_analysis(line_2,naive_bayes_dict.get('word_counts'),naive_bayes_dict.get('class_priors'),naive_bayes_dict.get('class_probs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d6cbb06-3ba6-42eb-aa52-19875dbeabc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Angry'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_2_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18cc3e8c-015e-48c4-a274-20a17225222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_3 = 'I AM DELIGHTED BY YOUR FRIENDLINESS AND YOU ALWAYS MAKE EVERYONE FEEL WELCOME WHICH FOSTERS A SENSE OF COMMUNITY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6bda431-21d5-4132-849c-3cf4283ea2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry_prob is -65.18889489096102\n",
      "happy_prob is -59.022055432740004\n",
      "neutral_prob is -73.35421064676792\n"
     ]
    }
   ],
   "source": [
    "line_3_class = sentiment_analysis(line_3,naive_bayes_dict.get('word_counts'),naive_bayes_dict.get('class_priors'),naive_bayes_dict.get('class_probs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51dcc182-66af-4362-9806-4180a1804c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happy'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_3_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a77ecfe9-223b-4748-ba65-0ba93633d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_4 = 'IT IS WONDERFULL THAT YOU ALWAYS SHOW KINDNESS AND YOUR EMPATHY TOWARDS OTHERS IS TRULY HEARTWARMING AND APPRECIATED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50149c56-fe54-4c93-97c5-f6bfdc97935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry_prob is -47.62306359715982\n",
      "happy_prob is -45.00072806828581\n",
      "neutral_prob is -60.08101637966102\n"
     ]
    }
   ],
   "source": [
    "line_4_class = sentiment_analysis(line_4,naive_bayes_dict.get('word_counts'),naive_bayes_dict.get('class_priors'),naive_bayes_dict.get('class_probs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bd18c7f-4839-4df7-a218-2c43461de383",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_5 = 'YOUR ANALYSIS OF THE DATA WAS ACCURATE AND WELL PRESENTED PROVIDING A CLEAR UNDERSTANDING OF THE TRENDS AND PATTERNS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "262407a2-48a8-470b-b978-35a3a824bb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry_prob is -55.19966146773303\n",
      "happy_prob is -56.33727781640785\n",
      "neutral_prob is -44.469507346411596\n"
     ]
    }
   ],
   "source": [
    "line_5_class = sentiment_analysis(line_5,naive_bayes_dict.get('word_counts'),naive_bayes_dict.get('class_priors'),naive_bayes_dict.get('class_probs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3081e56-f628-46d6-b283-c636d19571c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_5_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "202643b0-eab2-4f3d-9358-0b3c2f20e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_6 = 'THE MEETING MINUTES YOU PREPARED WAS DETAILED AND WELL ORGANISED ACCURATELY REFLECTING THE DISCUSSIONS AND DECESIONS MADE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a1a8df4-864d-451d-a621-790b9e0abf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry_prob is -47.080365294797126\n",
      "happy_prob is -46.00307837302877\n",
      "neutral_prob is -39.224392295272764\n"
     ]
    }
   ],
   "source": [
    "line_6_class = sentiment_analysis(line_6,naive_bayes_dict.get('word_counts'),naive_bayes_dict.get('class_priors'),naive_bayes_dict.get('class_probs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93ba971e-ff90-4dc3-8c03-34429d751795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_6_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d1956-6eac-4931-afe3-4cbb3ed8f02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epoch_task_2",
   "language": "python",
   "name": "epoch_task_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
